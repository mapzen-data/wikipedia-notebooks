{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from all_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine jsons from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_json = '../OUTPUTS_languages'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_languages_dict={}\n",
    "for js in json_files:\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        new_json=json.load(json_file)\n",
    "    all_languages_dict.update(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of languages with wof:id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wof_ids = read_data(\"..\\Analyzed_data\\\\final_titles_ids_all_status.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_dic_wof_name={}\n",
    "for index, row in wof_ids.iterrows():\n",
    "    key = row['wk:page']\n",
    "    value = str(int(row['wof:id']))\n",
    "    mapping_dic_wof_name.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_dic_name_wof={}\n",
    "for index, row in wof_ids.iterrows():\n",
    "    key = str(int(row['wof:id']))\n",
    "    value = row['wk:page']\n",
    "    mapping_dic_name_wof.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_wof_languages={}\n",
    "for key, value in all_languages_dict.iteritems():\n",
    "    try:\n",
    "        a = key.encode('utf8')\n",
    "        new_key=mapping_dic_wof_name[a]\n",
    "        dictionary_wof_languages.update({new_key:value})\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discard names that were not cleaned up - see titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('..\\Jupyter_notebooks_with_analysis\\\\names_do_not_want', 'rb') as f:\n",
    "    names_do_not_want = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wof_do_not_want = []\n",
    "for item in names_do_not_want:\n",
    "    wof = int(item)\n",
    "    wof_do_not_want.append(wof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = []\n",
    "for x in wof_do_not_want:\n",
    "    if type(x) is list:\n",
    "        flattened.extend(x)\n",
    "    else:\n",
    "        flattened.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_set=set(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_wof_languages_clean={}\n",
    "for key, value in dictionary_wof_languages.iteritems():\n",
    "    if key in names_set:\n",
    "        pass\n",
    "    else:\n",
    "        dictionary_wof_languages_clean.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('..\\Analyzed_data\\\\languages_dict_clean_wof.json', 'w') as outfile:\n",
    "    json.dump(dictionary_wof_languages, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean language names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary_names_languages_clean={}\n",
    "for key, value in dictionary_wof_languages_clean.iteritems():\n",
    "    try:\n",
    "        new_key=mapping_dic_name_wof[key]\n",
    "        dictionary_names_languages_clean.update({new_key:value})\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('..\\Analyzed_data\\\\languages_dict_clean.json', 'w') as outfile:\n",
    "    json.dump(dictionary_names_languages_clean, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean languages from placetypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_wof_clean_all = {}\n",
    "for key , values in dictionary_names_languages_clean.iteritems():\n",
    "    dic_wof_values_clean = {}\n",
    "    for lang, value in values.iteritems():\n",
    "        if value.find(\" (\") != -1:\n",
    "            lhs, rhs = value.split(\" (\",1)\n",
    "            new_value = lhs\n",
    "        elif value.find(\",\") != -1:\n",
    "            lhs, rhs = value.split(\",\",1)\n",
    "            new_value = lhs\n",
    "        else:\n",
    "            new_value = value\n",
    "        dic_wof_values_clean.update({lang:new_value})\n",
    "    dic_wof_clean_all.update({key:dic_wof_values_clean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('..\\Analyzed_data\\\\languages_wof_dict_clean_values.json', 'w') as outfile:\n",
    "    json.dump(dic_wof_clean_all, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
